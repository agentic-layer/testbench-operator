apiVersion: testworkflows.testkube.io/v1
kind: TestWorkflowTemplate
metadata:
  name: ragas-evaluate-template
  namespace: testkube
  labels:
    testkube.io/test-category: ragas-evaluation
    app: testworkflows
spec:
  # Configuration parameters that can be overridden
  config:
    model:
      type: string
      description: "Model name to use for evaluation (e.g., gemini-2.5-flash-lite)"
    metricsConfigPath:
      type: string
      description: "Path to metrics configuration file (JSON or YAML)"
      default: "config/metrics.yaml"
    image:
      type: string
      description: "Docker image to use for the evaluate step"
      default: "ghcr.io/agentic-layer/testbench/testworkflows:0.1.1"

  # Steps to execute
  steps:
    - name: evaluate-results
      artifacts:
        paths:
          - "data/results/evaluation_scores.json"
      run:
        command:
          - sh
          - -c
        args:
          - |
            uv run python3 evaluate.py "{{ config.model }}" --metrics-config "{{ config.metricsConfigPath }}" && \
            if [ -f data/results/evaluation_scores.json ]; then
              echo "✓ Evaluation completed"
              cat data/results/evaluation_scores.json
            else
              echo "✗ Error: Results file not created"
              exit 1
            fi
